Spark context Web UI available at http://10.27.162.167:4040
Spark context available as 'sc' (master = local[*], app id = local-1528288688999).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.2.1
      /_/
         
Using Scala version 2.11.8 (OpenJDK 64-Bit Server VM, Java 1.8.0_171)
Type in expressions to have them evaluated.
Type :help for more information.

scala> 

scala> 

scala> val bigText = sc.textFile("big.txt")
bigText: org.apache.spark.rdd.RDD[String] = big.txt MapPartitionsRDD[1] at textFile at <console>:24

scala> 

scala> val lines = bigText.flatMap(line => line.split("\\s"))
lines: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[2] at flatMap at <console>:26

scala> 

scala> val words = lines.map(_.replaceAll("[{~,!,@,#,$,%,^,&,*,(,),_,=,-,`,:,',? ,/,<,>,.}]", "").trim.toLowerCase)
words: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[3] at map at <console>:28

scala> 

scala> val filteredWords = words.filter(word => !word.isEmpty && word.matches("[ A-Za-z]+")).map(word => (word,1)).reduceByKey(_+_)
filteredWords: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[6] at reduceByKey at <console>:30

scala> 

scala> 

scala> :quit
